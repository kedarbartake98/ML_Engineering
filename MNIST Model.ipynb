{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, AveragePooling2D, Dense, Activation, Flatten, Dropout\n",
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train),(X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, 1)\n",
    "X_test = np.expand_dims(X_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 8, 28, 28)         72        \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 8, 28, 28)         112       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 8, 28, 28)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 8, 14, 14)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 14, 14)        1152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, 14, 14)        56        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16, 14, 14)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 16, 7, 7)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 7, 7)          2304      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 7, 7)          28        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 7, 7)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 7, 7)          0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 16, 4, 4)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 4, 4)          4608      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 4, 4)          16        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32, 4, 4)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 4, 4)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 4, 4)          2890      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 10, 1, 1)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 11,238\n",
      "Trainable params: 11,132\n",
      "Non-trainable params: 106\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(8, kernel_size=(3,3), padding='same', use_bias=False, input_shape=(1,28,28)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(AveragePooling2D((2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(3,3), padding='same', use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(AveragePooling2D((2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(3,3), padding='same', use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(AveragePooling2D((2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3,3), padding='same', use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(10, kernel_size=(3,3), padding='same'))\n",
    "model.add(AveragePooling2D((4,4), strides=(4,4), padding='same'))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 1.2903 - accuracy: 0.6038 - val_loss: 0.9218 - val_accuracy: 0.8348\n",
      "Epoch 2/30\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3535 - accuracy: 0.8966 - val_loss: 0.2212 - val_accuracy: 0.9497\n",
      "Epoch 3/30\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.2345 - accuracy: 0.9297 - val_loss: 0.1586 - val_accuracy: 0.9527\n",
      "Epoch 4/30\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.1865 - accuracy: 0.9436 - val_loss: 0.1162 - val_accuracy: 0.9650\n",
      "Epoch 5/30\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.1575 - accuracy: 0.9521 - val_loss: 0.0963 - val_accuracy: 0.9712\n",
      "Epoch 6/30\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.1434 - accuracy: 0.9556 - val_loss: 0.0959 - val_accuracy: 0.9715\n",
      "Epoch 7/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.1243 - accuracy: 0.9622 - val_loss: 0.0809 - val_accuracy: 0.9761\n",
      "Epoch 8/30\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.1103 - accuracy: 0.9656 - val_loss: 0.0718 - val_accuracy: 0.9774\n",
      "Epoch 9/30\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.1052 - accuracy: 0.9678 - val_loss: 0.0646 - val_accuracy: 0.9806\n",
      "Epoch 10/30\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.0963 - accuracy: 0.9699 - val_loss: 0.0614 - val_accuracy: 0.9802\n",
      "Epoch 11/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0888 - accuracy: 0.9723 - val_loss: 0.0541 - val_accuracy: 0.9826\n",
      "Epoch 12/30\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.0853 - accuracy: 0.9735 - val_loss: 0.0554 - val_accuracy: 0.9823\n",
      "Epoch 13/30\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.0816 - accuracy: 0.9749 - val_loss: 0.0490 - val_accuracy: 0.9845\n",
      "Epoch 14/30\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.0797 - accuracy: 0.9748 - val_loss: 0.0477 - val_accuracy: 0.9852\n",
      "Epoch 15/30\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.0721 - accuracy: 0.9774 - val_loss: 0.0495 - val_accuracy: 0.9851\n",
      "Epoch 16/30\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.0717 - accuracy: 0.9778 - val_loss: 0.0522 - val_accuracy: 0.9847\n",
      "Epoch 17/30\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.0684 - accuracy: 0.9785 - val_loss: 0.0456 - val_accuracy: 0.9870\n",
      "Epoch 18/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0644 - accuracy: 0.9802 - val_loss: 0.0448 - val_accuracy: 0.9877\n",
      "Epoch 19/30\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0644 - accuracy: 0.9797 - val_loss: 0.0385 - val_accuracy: 0.9880\n",
      "Epoch 20/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0592 - accuracy: 0.9811 - val_loss: 0.0410 - val_accuracy: 0.9881\n",
      "Epoch 21/30\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.0595 - accuracy: 0.9816 - val_loss: 0.0426 - val_accuracy: 0.9880\n",
      "Epoch 22/30\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.0566 - accuracy: 0.9817 - val_loss: 0.0435 - val_accuracy: 0.9858\n",
      "Epoch 23/30\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.0554 - accuracy: 0.9824 - val_loss: 0.0467 - val_accuracy: 0.9855\n",
      "Epoch 24/30\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.0550 - accuracy: 0.9827 - val_loss: 0.0376 - val_accuracy: 0.9896\n",
      "Epoch 25/30\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.0560 - accuracy: 0.9824 - val_loss: 0.0369 - val_accuracy: 0.9893\n",
      "Epoch 26/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0524 - accuracy: 0.9835 - val_loss: 0.0419 - val_accuracy: 0.9879\n",
      "Epoch 27/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0509 - accuracy: 0.9838 - val_loss: 0.0395 - val_accuracy: 0.9884\n",
      "Epoch 28/30\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 0.0490 - accuracy: 0.9845 - val_loss: 0.0417 - val_accuracy: 0.9870\n",
      "Epoch 29/30\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.0500 - accuracy: 0.9842 - val_loss: 0.0425 - val_accuracy: 0.9878\n",
      "Epoch 30/30\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.0472 - accuracy: 0.9855 - val_loss: 0.0377 - val_accuracy: 0.9893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8548219198>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=256 ,epochs=30, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = model.predict(X_test)\n",
    "y_pred = np.argmax(y_predict, 1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.argmax(y_test, 1)\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       980\n",
      "           1       0.99      1.00      0.99      1135\n",
      "           2       0.98      0.99      0.99      1032\n",
      "           3       0.99      0.99      0.99      1010\n",
      "           4       0.99      0.99      0.99       982\n",
      "           5       0.99      0.99      0.99       892\n",
      "           6       0.99      0.99      0.99       958\n",
      "           7       0.97      1.00      0.98      1028\n",
      "           8       1.00      0.98      0.99       974\n",
      "           9       0.99      0.98      0.99      1009\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../mnist_cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving random images for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1, 28, 28)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "np.random.shuffle(X_test)\n",
    "samples=X_test[0:10]\n",
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(samples.shape[0]):\n",
    "    \n",
    "    img = Image.fromarray(samples[i,0,:,:])\n",
    "    img.save('../test_data/sample{}.png'.format(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
